\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{geometry}
\geometry{margin=2.5cm}

\title{Sprawozdanie z Laboratorium \\ Obliczenia Numeryczne}
\author{Paweł Grzegory}
\date{\today}

\begin{document}

\maketitle

\section{}
 
\subsection{Wyznaczanie epsilona maszynowego}

Celem zadania jest iteracyjne wyznaczenie epsilona maszynowego (macheps).
Epsilonem maszynowym (macheps) nazywamy najmniejszą dodatnią liczbę $\epsilon$ taką, że $\mathrm{fl}(1+\epsilon)>1$, gdzie $\mathrm{fl}$ oznacza operację zaokrąglenia w arytmetyce zmiennoprzecinkowej. Innymi słowy, macheps to odległość 1.0 od następnej reprezentowalnej liczby większej od 1.

Poniższa tabela porównuje iteracyjnie wyznaczone wartości z wynikami wbudowanej funkcji \texttt{eps()} w języku Julia.


\begin{center}
\begin{tabular}{l c c c}
\hline
Typ danych & Obliczony epsilon & \texttt{eps()} z Julii & Różnica \\
\hline
\texttt{Float16} & 9.765625000000000e-04 & 9.765625000000000e-04 & 0.000000000000000e+00 \\
\texttt{Float32} & 1.192092895507812e-07 & 1.192092895507812e-07 & 0.000000000000000e+00 \\
\texttt{Float64} & 2.220446049250313e-16 & 2.220446049250313e-16 & 0.000000000000000e+00 \\
\hline
\end{tabular}
\end{center}

Iteracyjnie wyznaczony epsilon maszynowy jest identyczny z epsilonem zwracanym przez funkcje
bibloteczne z Juli


\subsubsection*{Porównanie z typami w języku C}
Dla porównania, poniżej przedstawiono standardowe wartości epsilona dla typów zmiennoprzecinkowych w języku C, zdefiniowane w pliku nagłówkowym \texttt{float.h}.

\begin{flushleft}
\begin{tabular}{@{}l c@{}}
\hline
Typ danych & Epsilon \\
\hline
\texttt{float} & 1.192093e-07 \\
\texttt{double} & 2.220446e-16 \\
\texttt{long double} & 1.084202e-19 \\
\hline
\end{tabular}
\end{flushleft}

Przedstawione dane pokazują, że typy

\subsection{}

Celem zadania jest wyznaczanie najmniejszej dodatniej liczby maszynowej (eta) dla wybranych typów zmiennoprzecinkowych:

\subsubsection*{Wyniki dla eta}
\begin{center}
\begin{tabular}{l c c l}
\hline
Typ danych & Iteracyjnie & \texttt{nextfloat(0.0)} & Uwagi \\
\hline
\texttt{Float16} & 6.0e-8 & 6.0e-8 & Wyniki są identyczne. \\
\texttt{Float32} & 1.0e-45 & 1.0e-45 & Wyniki są identyczne. \\
\texttt{Float64} & 5.0e-324 & 5.0e-324 & Wyniki są identyczne. \\
\hline
\end{tabular}
\end{center}

Wyniki eksperymentu są zgodne z wartościami zwracanymi przez funkcję \texttt{nextfloat(T(0.0))}, która podaje następną reprezentowalną liczbę po zerze.

\subsubsection{Związek matcheps z precyzją arytmetyki}
Niech $\beta$ będzie podstawą systemu, a $t$ liczbą cyfr w mantysie (precyzją). Przy zaokrąglaniu do najbliższej wartości mamy:
\begin{align}
\mathrm{macheps} &= \mathrm{nextfloat}(1.0) - 1.0 \\
&= \bigl(1.000\ldots01\bigr)_\beta\beta^{0} - \bigl(1.000\ldots00\bigr)_\beta\beta^{0} \\
&= \beta^{-(t-1)} = \beta^{\,1-t}.
\end{align}
\[
\epsilon \;=\; \tfrac{1}{2}\,\beta^{\,1-t} \;=\; \tfrac{1}{2}\,\mathrm{macheps},
\]
czyli błąd zaokrąglenia jest rzędu $\mathrm{macheps}/2$.

\subsubsection{związek liczby eta z liczbą \(MIN_{\text{sub}}\)}
\(\eta\) definiuje się jako najmniejszą dodatnią liczbę maszynową (MINsub). Zatem
\[
\eta \;=\; \mathrm{MIN_{\text{sub}}}.
\]
Dla arytmetyki o podstawie \(\beta\), precyzji \(t\) i najmniejszym wykładniku normalnym \(c_{\min}\) zachodzi
\[
\eta \;=\; \beta^{\,c_{\min}-(t-1)} \;=\; \beta^{c_{\min}}\beta^{1-t},
\]

\subsubsection{Wartości zwracacane przez floatmin(Float32) i floatmin(Float64)}
\begin{center}
\begin{tabular}{@{}l c@{}}
\hline
Typ & Wartość z funkcji \texttt{floatmin} \\
\hline
\texttt{Float16} & 6.104e-5 \\
\texttt{Float32} & 1.1754944e-38 \\
\texttt{Float64} & 2.2250738585072014e-308 \\
\hline
\end{tabular}
\end{center}

\texttt{floatmin(Type)} -- zwraca najmniejszą wartość dodatnią znormalizowaną dla typu \texttt{Type}.

Dla najmniejszej liczby subnormalnej (MINsub) można zapisać:
\[
\mathrm{MINsub} = 2^{c_{\min}} = floatmin.
\]

\subsection{ 1.3 Wyznaczanie największej liczby maszynowej}

Wyznaczanie największej liczby maszynowej (max):

\begin{center}
\begin{tabular}{@{}l l l@{}}
\hline
Typ & Wyznaczona największa liczba & Wartość z funkcji \texttt{floatmax} \\
\hline
\texttt{Float16} & 6.55e4 & 6.55e4 \\
\texttt{Float32} & 3.4028235e38 & 3.4028235e38 \\
\texttt{Float64} & 1.7976931348623157e308 & 1.7976931348623157e308 \\
\hline
\end{tabular}
\end{center}

Typy w c

\begin{center}
\begin{tabular}{@{}l c@{}}
\hline
Typ & Maksymalna wartość \\
\hline
\texttt{float} & 3.402823e+38 \\
\texttt{double} & 1.797693e+308 \\
\texttt{long double} & 1.189731e+4932 \\
\hline
\end{tabular}
\end{center}

\section{ Sprawozdanie słuszności twierdzenia Khana}
Celem eksperymentu jest weryfikacja metody zaproponowanej przez Williama Khana do obliczania epsilona maszynowego oraz porównanie jej wyników z wartościami zwracanymi przez standardową funkcję \texttt{eps()} w języku Julia.

Metoda Khana polega na obliczeniu wyrażenia:
\[ \epsilon_K = 3 \cdot (\frac{4}{3} - 1) - 1 \]
W idealnej arytmetyce wynik tego działania powinien wynosić 0. Jednak w arytmetyce zmiennoprzecinkowej, błędy zaokrągleń powstające podczas operacji dzielenia i odejmowania powodują, że końcowy wynik jest bliski epsilonowi maszynowemu.

Poniżej przedstawiono wyniki obliczeń metodą Khana oraz wartości funkcji \texttt{eps()} z Julii.

\begin{center}
\begin{tabular}{l c c}
\hline
Typ & Khan Epsilon & \texttt{eps()} z Julii \\
\hline
\texttt{Float16} & -0.000977 & 0.000977 \\
\texttt{Float32} & 1.1920929e-7 & 1.1920929e-7 \\
\texttt{Float64} & -2.220446049250313e-16 & 2.220446049250313e-16 \\
\hline
\end{tabular}
\end{center}

Jak widać w tabeli, wartości bezwzględne epsilona wyznaczonego metodą Khana są równe wartościom zwracanym przez funkcję \texttt{eps()} 
dla wszystkich testowanych typów. Różnica w znaku dla typów \texttt{Float16} oraz \texttt{Float64} wynika ze sposobu zaokrąglania liczby $4/3$ w tych standardach. W przypadku zaokrąglenia w dół (round-down), wynik operacji $4/3 - 1$ jest nieco mniejszy niż $1/3$, co po pomnożeniu przez 3 i odjęciu 1 daje wartość ujemną. Natomiast dla typu \texttt{Float32}, zaokrąglenie w górę (round-up) prowadzi do wyniku dodatniego. Eksperyment potwierdza, że metoda Khana jest skutecznym sposobem na oszacowanie rzędu wielkości epsilona maszynowego.

\section{}

\section{Znajdowanie liczby \(x\), dla której \(x \cdot (1/x) \neq 1\)}
Celem zadania jest znaleznienie takiego \(x\), dla którego zachodzi \(x \cdot (1/x) \neq 1\)

Przeprowadzono eksperyment polegający na iteracyjnym przeszukiwaniu kolejnych liczb maszynowych typu \texttt{Float64} w celu znalezienia wartości \(x\), dla której wspomniana tożsamość nie jest prawdziwa.

Poniżej przedstawiono wyniki programu wyszukującego liczbę \(x\), dla której iloczyn \(x \cdot (1/x)\) nie jest równy 1.

\begin{center}
\begin{tabular}{@{}l l@{}}
\hline
Zakres / opis & Znaleziona wartość \\
\hline
Dla zakresu \([1,2]\) & \texttt{1.000000057228997} \\
Najmniejsza znaleziona wartość & \texttt{5.0e-324} \\
\hline
\end{tabular}
\end{center}

\subsection*{Analiza wyników}
\begin{itemize}
    \item \textbf{Dla zakresu \([1,2]\):} Znaleziona wartość \texttt{1.000000057228997} pokazuje, że nawet dla liczb o "rozsądnej" wielkości, błędy zaokrąglenia mogą się kumulować. Operacja dzielenia \texttt{1.0 / x} produkuje wynik, który musi zostać zaokrąglony do najbliższej reprezentowalnej liczby maszynowej. Następnie, mnożenie tego wyniku z powrotem przez \(x\) może wprowadzić kolejny błąd zaokrąglenia, co w sumie prowadzi do rezultatu różnego od 1.
    \item \textbf{Najmniejsza znaleziona wartość:} Wartość \texttt{5.0e-324} jest najmniejszą dodatnią liczbą w standardzie \texttt{Float64}. Dla tak małych liczb (bliskich zeru), operacja odwrotności \texttt{1.0 / x} daje bardzo duży wynik, bliski granicy zakresu reprezentacji. Mnożenie tak dużej liczby przez pierwotną, bardzo małą wartość \(x\) jest szczególnie podatne na błędy zaokrągleń, co prowadzi do niedokładności. Eksperyment pokazuje, że już dla najmniejszej możliwej do reprezentowania dodatniej liczby, tożsamość nie jest spełniona.
\end{itemize}
Eksperyment ten ilustruje ograniczenia arytmetyki zmiennoprzecinkowej.



\section{Obliczanie iloczynu skalarnego x i y}
\begin{center}
\begin{tabular}{@{}l c c c c@{}}
\hline
Typ & (a) W przód & (b) W tył & (c) Od największego & (d) Od najmniejszego \\
\hline
\texttt{Float32} & -0.4999443 & -0.4543457 & -0.5 & -0.5 \\
\texttt{Float64} & 1.0251881368296672e-10 & -1.5643308870494366e-10 & 0.0 & 0.0 \\
\hline
\end{tabular}
\end{center}

\section{Porównanie wartości funkcji f(n) i g(n)}


\begin{center}
\begin{tabular}{@{}c l l@{}}
\hline
\(n\) & Wartość \(f(n)\) & Wartość \(g(n)\) \\
\hline
1 & 0.0077822185373186414 & 0.0077822185373187065 \\
2 & 0.00012206286282867573 & 0.00012206286282875901 \\
3 & 1.9073468138230965e-6 & 1.907346813826566e-6 \\
4 & 2.9802321943606103e-8 & 2.9802321943606116e-8 \\
5 & 4.656612873077393e-10 & 4.6566128719931904e-10 \\
6 & 7.275957614183426e-12 & 7.275957614156956e-12 \\
7 & 1.1368683772161603e-13 & 1.1368683772160957e-13 \\
8 & 1.7763568394002505e-15 & 1.7763568394002489e-15 \\
9 & 0.0 & 2.7755575615628914e-17 \\
10 & 0.0 & 4.336808689942018e-19 \\
11 & 0.0 & 6.776263578034403e-21 \\
12 & 0.0 & 1.0587911840678754e-22 \\
13 & 0.0 & 1.6543612251060553e-24 \\
14 & 0.0 & 2.5849394142282115e-26 \\
15 & 0.0 & 4.0389678347315804e-28 \\
16 & 0.0 & 6.310887241768095e-30 \\
17 & 0.0 & 9.860761315262648e-32 \\
18 & 0.0 & 1.5407439555097887e-33 \\
19 & 0.0 & 2.407412430484045e-35 \\
20 & 0.0 & 3.76158192263132e-37 \\
\hline
\end{tabular}
\end{center}

Jak widać w tabeli, wartości \(f(n)\) i \(g(n)\) różnią się dla każdego \(n\). Dla \(n \ge 9\), wartość \(f(n)\) staje się zerem z powodu błędów zaokrągleń w obliczeniach, podczas gdy (\(g(n)\)) pozostaje stabilna i daje niezerowe wyniki.

\section{}

Dokładna wartość pochodnej f'(1.0) = 0.11694228168853815
\begin{center}
\footnotesize
\begin{tabular}{c l l l l l}
\hline
n & h & Przybliżona pochodna & Błąd absolutny & Błąd względny & 1.0 + h \\
\hline
0 & 1.000000000000000e+00 & 2.017989225268597 & 1.901046943580059e+00 & 1.625628400721025e+01 & 2.000000000000000 \\
1 & 5.000000000000000e-01 & 1.870441397931647 & 1.753499116243109e+00 & 1.499456903802634e+01 & 1.500000000000000 \\
2 & 2.500000000000000e-01 & 1.107787095234297 & 9.908448135457593e-01 & 8.472938951069525e+00 & 1.250000000000000 \\
3 & 1.250000000000000e-01 & 0.623241279297582 & 5.062989976090435e-01 & 4.329477673075600e+00 & 1.125000000000000 \\
4 & 6.250000000000000e-02 & 0.370400066203519 & 2.534577845149810e-01 & 2.167375057637713e+00 & 1.062500000000000 \\
5 & 3.125000000000000e-02 & 0.243443074397547 & 1.265007927090087e-01 & 1.081736997794592e+00 & 1.031250000000000 \\
6 & 1.562500000000000e-02 & 0.180097563307328 & 6.315528161878969e-02 & 5.400551511984029e-01 & 1.015625000000000 \\
7 & 7.812500000000000e-03 & 0.148491395371096 & 3.154911368255764e-02 & 2.697836336611333e-01 & 1.007812500000000 \\
8 & 3.906250000000000e-03 & 0.132709114280516 & 1.576683259197775e-02 & 1.348257650211652e-01 & 1.003906250000000 \\
9 & 1.953125000000000e-03 & 0.124823692940708 & 7.881411252170345e-03 & 6.739573692568737e-02 & 1.001953125000000 \\
10 & 9.765625000000000e-04 & 0.120882476811062 & 3.940195122523527e-03 & 3.369350303098897e-02 & 1.000976562500000 \\
11 & 4.882812500000000e-04 & 0.118912250468838 & 1.969968780300313e-03 & 1.684565028025612e-02 & 1.000488281250000 \\
12 & 2.441406250000000e-04 & 0.117927233739010 & 9.849520504721099e-04 & 8.422548596199042e-03 & 1.000244140625000 \\
13 & 1.220703125000000e-04 & 0.117434749610766 & 4.924679222275685e-04 & 4.211205007434336e-03 & 1.000122070312500 \\
14 & 6.103515625000000e-05 & 0.117188513620931 & 2.462319323930373e-04 & 2.105585155665482e-03 & 1.000061035156250 \\
15 & 3.051757812500000e-05 & 0.117065397145780 & 1.231154572414184e-04 & 1.052788225642131e-03 & 1.000030517578125 \\
16 & 1.525878906250000e-05 & 0.117003839288373 & 6.155759983439424e-05 & 5.263930115400482e-04 & 1.000015258789062 \\
17 & 7.629394531250000e-06 & 0.116973060459713 & 3.077877117529937e-05 & 2.631962599915312e-04 & 1.000007629394531 \\
18 & 3.814697265625000e-06 & 0.116957671067212 & 1.538937867362478e-05 & 1.315980708723690e-04 & 1.000003814697266 \\
19 & 1.907348632812500e-06 & 0.116949976363685 & 7.694675146829866e-06 & 6.579891409442238e-05 & 1.000001907348633 \\
20 & 9.536743164062500e-07 & 0.116946129011922 & 3.847323383432411e-06 & 3.289933570544911e-05 & 1.000000953674316 \\
21 & 4.768371582031250e-07 & 0.116944205248728 & 1.923560190242313e-06 & 1.644879989057753e-05 & 1.000000476837158 \\
22 & 2.384185791015625e-07 & 0.116943242959678 & 9.612711400208696e-07 & 8.220047754678678e-06 & 1.000000238418579 \\
23 & 1.192092895507812e-07 & 0.116942762397230 & 4.807086915192826e-07 & 4.110649155962195e-06 & 1.000000119209290 \\
24 & 5.960464477539062e-08 & 0.116942521184683 & 2.394961446938737e-07 & 2.047985905831247e-06 & 1.000000059604645 \\
25 & 2.980232238769531e-08 & 0.116942398250103 & 1.165615648446305e-07 & 9.967444038340076e-07 & 1.000000029802322 \\
26 & 1.490116119384766e-08 & 0.116942338645458 & 5.695692006923991e-08 & 4.870515543808004e-07 & 1.000000014901161 \\
27 & 7.450580596923828e-09 & 0.116942316293716 & 3.460517827846843e-08 & 2.959167358358476e-07 & 1.000000007450581 \\
28 & 3.725290298461914e-09 & 0.116942286491394 & 4.802855890773117e-09 & 4.107031110924406e-08 & 1.000000003725290 \\
29 & 1.862645149230957e-09 & 0.116942226886749 & 5.480178888461751e-08 & 4.686225383439632e-07 & 1.000000001862645 \\
30 & 9.313225746154785e-10 & 0.116942167282104 & 1.144064336600081e-07 & 9.783153877971703e-07 & 1.000000000931323 \\
31 & 4.656612873077393e-10 & 0.116942167282104 & 1.144064336600081e-07 & 9.783153877971703e-07 & 1.000000000465661 \\
32 & 2.328306436538696e-10 & 0.116941928863525 & 3.528250127615706e-07 & 3.017086785609999e-06 & 1.000000000232831 \\
33 & 1.164153218269348e-10 & 0.116941452026367 & 8.296621709646956e-07 & 7.094629581235657e-06 & 1.000000000116415 \\
34 & 5.820766091346741e-11 & 0.116941452026367 & 8.296621709646956e-07 & 7.094629581235657e-06 & 1.000000000058208 \\
35 & 2.910383045673370e-11 & 0.116939544677734 & 2.737010803777196e-06 & 2.340480076373829e-05 & 1.000000000029104 \\
36 & 1.455191522836685e-11 & 0.116943359375000 & 1.077686461847804e-06 & 9.215541601266973e-06 & 1.000000000014552 \\
37 & 7.275957614183426e-12 & 0.116928100585938 & 1.418110260065220e-05 & 1.212658278587541e-04 & 1.000000000007276 \\
38 & 3.637978807091713e-12 & 0.116943359375000 & 1.077686461847804e-06 & 9.215541601266973e-06 & 1.000000000003638 \\
39 & 1.818989403545856e-12 & 0.116882324218750 & 5.995746978815220e-05 & 5.127099362388172e-04 & 1.000000000001819 \\
40 & 9.094947017729282e-13 & 0.116821289062500 & 1.209926260381522e-04 & 1.034635414078901e-03 & 1.000000000000909 \\
41 & 4.547473508864641e-13 & 0.116943359375000 & 1.077686461847804e-06 & 9.215541601266973e-06 & 1.000000000000455 \\
42 & 2.273736754432321e-13 & 0.116699218750000 & 2.430629385381522e-04 & 2.078486369759070e-03 & 1.000000000000227 \\
43 & 1.136868377216160e-13 & 0.116210937500000 & 7.313441885381522e-04 & 6.253890192479743e-03 & 1.000000000000114 \\
44 & 5.684341886080801e-14 & 0.117187500000000 & 2.452183114618478e-04 & 2.096917452961604e-03 & 1.000000000000057 \\
45 & 2.842170943040401e-14 & 0.113281250000000 & 3.661031688538152e-03 & 3.130631312880378e-02 & 1.000000000000028 \\
46 & 1.421085471520200e-14 & 0.109375000000000 & 7.567281688538152e-03 & 6.470954371056917e-02 & 1.000000000000014 \\
47 & 7.105427357601002e-15 & 0.109375000000000 & 7.567281688538152e-03 & 6.470954371056917e-02 & 1.000000000000007 \\
48 & 3.552713678800501e-15 & 0.093750000000000 & 2.319228168853815e-02 & 1.983224660376307e-01 & 1.000000000000004 \\
49 & 1.776356839400250e-15 & 0.125000000000000 & 8.057718311461848e-03 & 6.890337861649237e-02 & 1.000000000000002 \\
50 & 8.881784197001252e-16 & 0.000000000000000 & 1.169422816885382e-01 & 1.000000000000000e+00 & 1.000000000000001 \\
51 & 4.440892098500626e-16 & 0.000000000000000 & 1.169422816885382e-01 & 1.000000000000000e+00 & 1.000000000000000 \\
52 & 2.220446049250313e-16 & -0.500000000000000 & 6.169422816885382e-01 & 5.275613514465969e+00 & 1.000000000000000 \\
53 & 1.110223024625157e-16 & 0.000000000000000 & 1.169422816885382e-01 & 1.000000000000000e+00 & 1.000000000000000 \\
54 & 5.551115123125783e-17 & 0.000000000000000 & 1.169422816885382e-01 & 1.000000000000000e+00 & 1.000000000000000 \\
\hline
\end{tabular}
\end{center}

Na podstawie przedstawionych danych można sformułować następujące wnioski:

Zmniejszanie kroku \(h\) w nie zawsze prowadzi do poprawy przybliżenia pochodnej z powodu dwóch przeciwstawnych źródeł błędów:
\begin{itemize}
    \item \textbf{Błąd obcięcia (truncation error):} Wynika on z samego przybliżenia matematycznego pochodnej ilorazem różnicowym. Jest on proporcjonalny do \(h\). Gdy \(h\) maleje, ten błąd również maleje. W tabeli widać, że dla \(n\) od 0 do około 28, błąd absolutny maleje wraz ze zmniejszaniem \(h\).
    \item \textbf{Błąd zaokrąglenia (round-off error):} Pojawia się, gdy \(h\) staje się bardzo małe. W arytmetyce zmiennoprzecinkowej, obliczenie \(x_0 + h\) dla \(x_0=1.0\) staje się niedokładne. Co ważniejsze, wartości \(f(x_0 + h)\) i \(f(x_0)\) są wtedy bardzo bliskie sobie. Ich odejmowanie w liczniku \(f(x_0 + h) - f(x_0)\) prowadzi do katastrofalnej utraty dokładności (ang. \textit{catastrophic cancellation}). Ten mały, niedokładny wynik jest następnie dzielony przez bardzo małe \(h\), co drastycznie wzmacnia błąd. W tabeli widać, że dla \(n > 28\), błąd absolutny zaczyna rosnąć, co świadczy o dominacji błędu zaokrąglenia.
\end{itemize}

\subsection*{Zachowanie wartości \(1+h\)}
Wartość \(1.0 + h\) zachowuje się zgodnie z oczekiwaniami dla arytmetyki \texttt{Float64}.
\begin{itemize}
    \item Dla \(n < 52\), \(h\) jest na tyle duże, że \(1.0 + h\) jest liczbą różną od \(1.0\).
    \item Dla \(n = 52\), \(h = 2^{-52} \approx 2.22 \times 10^{-16}\), co jest równe epsilonowi maszynowemu dla \texttt{Float64}. Wartość \(1.0 + h\) jest wciąż reprezentowana jako liczba większa od \(1.0\).
    \item Dla \(n > 52\), \(h\) staje się mniejsze niż połowa epsilona maszynowego. Wtedy w arytmetyce \texttt{Float64} suma \(1.0 + h\) jest zaokrąglana do \(1.0\). W konsekwencji licznik \(f(1.0 + h) - f(1.0)\) staje się \(f(1.0) - f(1.0) = 0\), a całe przybliżenie pochodnej wynosi 0 (jak widać dla \(n=53\) i \(n=54\)).
\end{itemize}

\subsection*{Porównanie z dokładną wartością}
Analizując kolumnę "Błąd absolutny", można zaobserwować:
\begin{itemize}
    \item \textbf{Poprawa:} Dla \(n\) od 0 do 28, błąd maleje o mniej więcej połowę z każdym krokiem, co jest zgodne z teorią dla błędu obcięcia rzędu \(O(h)\). Najmniejszy błąd (\(4.80 \times 10^{-9}\)) zostaje osiągnięty dla \(n=28\).
    \item \textbf{Pogorszenie:} Dla \(n > 28\), błąd zaczyna nieregularnie rosnąć. Jest to moment, w którym błąd zaokrąglenia zaczyna dominować nad błędem obcięcia.
    \item \textbf{Utrata znaczenia:} Dla bardzo dużych \(n\) (np. \(n=52\)), przybliżona wartość pochodnej (\(-0.5\)) jest całkowicie błędna, a błąd względny przekracza 500\%. To pokazuje, jak katastrofalna utrata precyzji zdominowała obliczenia.
\end{itemize}


\end{document}

